# =============================================================================
# FINAL SCRIPT V32.1 - Code Style Refactoring for Readability
# =============================================================================
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from lightgbm import LGBMRegressor
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import r2_score
from scipy.stats import spearmanr
import warnings
import time
from math import floor

# --- ç’°å¢ƒè¨­å®š ---
# ä½œç”¨: è¨­å®šåœ–å½¢é¡¯ç¤ºçš„å­—é«”èˆ‡å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Šï¼Œæå‡ä½¿ç”¨è€…é«”é©—ã€‚
try:
    plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] 
    plt.rcParams['axes.unicode_minus'] = False 
except Exception as e:
    print(f"å­—é«”è¨­å®šè­¦å‘Š: {e}ã€‚åœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚")
warnings.filterwarnings('ignore', category=FutureWarning)


# --- 1. çµ„æ…‹è¨­å®š (Config Class) ---
# ä½œç”¨: å°‡æ‰€æœ‰å¯èª¿æ•´çš„åƒæ•¸ã€æª”æ¡ˆè·¯å¾‘ã€æ¬„ä½åç¨±ç­‰é›†ä¸­ç®¡ç†ï¼Œæ–¹ä¾¿ä½¿ç”¨è€…å¿«é€Ÿä¿®æ”¹èˆ‡å¯¦é©—ï¼Œç„¡éœ€æ›´å‹•æ ¸å¿ƒç¨‹å¼ç¢¼ã€‚
class Config:
    # --- æª”æ¡ˆèˆ‡è·¯å¾‘è¨­å®š ---
    FILE_PATH = "data_final.xlsx"
    BENCHMARK_FILE_PATH = "e_index.xlsx"
    REPORT_FILE_PATH = 'strategy_reportcor5M.xlsx'

    # --- è³‡æ–™æ¬„ä½åç¨±è¨­å®š ---
    COMPANY_COL = 'StockID'
    DATE_COL = 'Date'
    PRICE_COL = 'Close'
    BENCHMARK_NAME = 'é›»å­å·¥æ¥­é¡æŒ‡æ•¸'

    # --- ç‰¹å¾µå› å­è¨­å®š ---
    # --- ç‰¹å¾µå› å­è¨­å®š ---
    # ä½œç”¨: è¨­å®šç”¨æ–¼æ¨¡å‹è¨“ç·´çš„ç‰¹å¾µæ¬„ä½åç¨±æ¸…å–®ï¼Œè«‹ç¢ºä¿åç¨±èˆ‡è³‡æ–™æ¬„ä½ä¸€è‡´ã€‚
    # FACTOR_COLS = [
    #     'Outstanding_Share_Million', 'Market_Cap', 'PB', 'Value', 'EBITDA_Margin',
    #     'ROA', 'ROE', 'Revenue_Growth', 'Total_Asset_Growth', 'Net_Worth_Growth',
    #     'Debt_Ratio', 'Dividend', 'Momentum', 'Std_Dev', 'Return',
    #     'Turnover','High', 'Low'
    # ]
    FACTOR_COLS = [
        'Market_Cap', 'PB', 'Value', 'EBITDA_Margin',
        'ROE', 'Revenue_Growth', 'Total_Asset_Growth', 'Net_Worth_Growth',
        'Debt_Ratio', 'Dividend', 'Momentum', 'Std_Dev', 'Return',
        'Turnover','Low'
    ]
    # --- é æ¸¬ç›®æ¨™è¨­å®š ---
    # ä½œç”¨: è¨­å®šæ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¦é æ¸¬çš„ç›®æ¨™æ¬„ä½åç¨±ã€é æ¸¬æœªä¾†å¹¾æ—¥çš„å ±é…¬ã€ä»¥åŠåŸå§‹èˆ‡æ¨™æº–åŒ–ç›®æ¨™æ¬„ä½ã€‚
    TARGET_COL = 'F_Return_20D_Z'  # æ¨™æº–åŒ–å¾Œçš„æœªä¾†20æ—¥å ±é…¬ (Zåˆ†æ•¸)
    FORWARD_RETURN_DAYS = 20       # é æ¸¬æœªä¾†å¹¾æ—¥çš„å ±é…¬ (æ­¤è™•ç‚º20æ—¥)
    RAW_TARGET_COL = f'F_Return_{FORWARD_RETURN_DAYS}D_Raw'  # æœªæ¨™æº–åŒ–çš„æœªä¾†20æ—¥å ±é…¬

    # --- è³‡æ–™é›†æ™‚é–“ç¯„åœè¨­å®š ---
    DATA_START_DATE = '2020-02-01'  # è³‡æ–™é›†èµ·å§‹æ—¥æœŸ
    TRAIN_END_DATE = '2023-12-31'   # è¨“ç·´é›†çµæŸæ—¥æœŸ
    TEST_START_DATE = '2024-01-01'  # æ¸¬è©¦é›†é–‹å§‹æ—¥æœŸ

    # --- æ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨­å®š ---
    RANDOM_STATE = 42  # éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    CV_SPLITS = 5      # äº¤å‰é©—è­‰åˆ†å‰²æ•¸
    N_ITER_SEARCH = 100  # éš¨æ©Ÿæœå°‹è¶…åƒæ•¸çš„æ¬¡æ•¸
    N_FEATURES_TO_SELECT = 5  # ç‰¹å¾µé¸æ“‡æ•¸é‡
    RANDOM_SEARCH_PARAM_DIST = {  # LightGBMè¶…åƒæ•¸æœå°‹ç©ºé–“
        'n_estimators': [100, 200, 300, 500],         # æ¨¹çš„æ•¸é‡
        'learning_rate': [0.01, 0.05, 0.1],           # å­¸ç¿’ç‡
        'num_leaves': [20, 31, 40, 50],               # æ¯æ£µæ¨¹çš„æœ€å¤§è‘‰å­æ•¸
        'max_depth': [5, 10, 15, -1],                 # æ¨¹çš„æœ€å¤§æ·±åº¦
        'reg_alpha': [0, 0.1, 0.5],                   # L1æ­£å‰‡åŒ–
        'reg_lambda': [0, 0.1, 0.5],                  # L2æ­£å‰‡åŒ–
        'colsample_bytree': [0.7, 0.8, 0.9]           # æ¯æ£µæ¨¹éš¨æ©Ÿæ¡æ¨£çš„ç‰¹å¾µæ¯”ä¾‹
    }

    # --- å›æ¸¬ç­–ç•¥è¨­å®š ---
    INITIAL_CAPITAL = 100000.0 # åˆå§‹è³‡é‡‘
    TRANSACTION_FEE_RATE = 0.001425 # äº¤æ˜“æ‰‹çºŒè²»ç‡ (0.1425%)
    TRANSACTION_TAX_RATE = 0.003 # äº¤æ˜“ç¨…ç‡ (0.3%)
    TOP_N_STOCKS = 10 # æ¯æœŸé¸æ“‡çš„è‚¡ç¥¨æ•¸é‡
    REBALANCE_FREQUENCY = 'M' # æ›å€‰é »ç‡ ('M' = æ¯æœˆ, 'Q' = æ¯å­£, 'Y' = æ¯å¹´)
    INDIVIDUAL_STOP_LOSS_PCT = 0.20 # å€‹è‚¡ç§»å‹•åœæç™¾åˆ†æ¯” (20%)
1

# --- 2. è¼”åŠ©ç¹ªåœ–èˆ‡è¨ˆç®—å‡½æ•¸ (Helpers) ---

# ä½œç”¨: ç¹ªè£½ç‰¹å¾µå› å­ä¹‹é–“çš„ç›¸é—œä¿‚æ•¸ç†±åŠ›åœ–ã€‚
def plot_correlation_heatmap(df, columns):
    print("\n>>> ç¹ªè£½ç‰¹å¾µç›¸é—œä¿‚æ•¸ç†±åŠ›åœ–...")
    valid_columns = [col for col in columns if col in df.columns]
    correlation_matrix = df[valid_columns].corr()
    
    plt.figure(figsize=(18, 14))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)
    plt.title('ç‰¹å¾µç›¸é—œä¿‚æ•¸ç†±åŠ›åœ– (è¨“ç·´é›†)', fontsize=16)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    print("âœ… åœ–è¡¨å·²ç”¢ç”Ÿã€‚")


# ä½œç”¨: ç¹ªè£½æ¨¡å‹è¨“ç·´å¾Œï¼Œå„ç‰¹å¾µçš„é‡è¦æ€§é•·æ¢åœ–ã€‚
def plot_feature_importance(importance, names, model_type):
    print(f"\n>>> ç¹ªè£½ {model_type} ç‰¹å¾µé‡è¦æ€§åœ–è¡¨...")
    fi_df = pd.DataFrame({
        'feature_names': names, 
        'feature_importance': importance
    }).sort_values(by='feature_importance', ascending=False)
    
    plt.figure(figsize=(10, 8))
    plt.barh(fi_df['feature_names'], fi_df['feature_importance'])
    plt.xlabel('ç‰¹å¾µé‡è¦æ€§')
    plt.ylabel('ç‰¹å¾µåç¨±')
    plt.title(f'{model_type} - ç‰¹å¾µé‡è¦æ€§', fontsize=16)
    plt.gca().invert_yaxis()
    plt.tight_layout()
    print("âœ… åœ–è¡¨å·²ç”¢ç”Ÿã€‚")


# ä½œç”¨: ç¹ªè£½æœ€çµ‚çš„ç¸¾æ•ˆåœ–ï¼Œä¸¦åœ¨åœ–ä¸Šæ¨™è¨»æ¯æœˆè³‡ç”¢æ•¸å­—ã€‚
def plot_backtest_results(performance_df, benchmark_perf_df=None):
    print("\n>>> ç¹ªè£½å›æ¸¬ç¸¾æ•ˆåœ–è¡¨...")
    fig, ax = plt.subplots(figsize=(16, 9))
    
    ax.stackplot(
        performance_df.index, 
        performance_df['Holdings_Value'], 
        performance_df['Cash'], 
        labels=['ç­–ç•¥æŒè‚¡å¸‚å€¼', 'ç­–ç•¥ç¾é‡‘'], 
        colors=['#3498db', '#bdc3c7'], 
        alpha=0.7
    )
    
    ax.plot(performance_df.index, performance_df['Total_Assets'], color='red', linewidth=2.5, label='ç­–ç•¥ç¸½è³‡ç”¢', marker='o', markersize=4)
    for date, row in performance_df.iterrows():
        total_assets = row['Total_Assets']
        label = f"{total_assets/1e6:.2f}M" if total_assets >= 1e6 else f"{total_assets/1e3:.0f}k"
        ax.annotate(label, (date, total_assets), textcoords="offset points", xytext=(0,10), ha='center', fontsize=9, color='blue')
    
    if benchmark_perf_df is not None and not benchmark_perf_df.empty:
        plot_benchmark_df = benchmark_perf_df[benchmark_perf_df.index.isin(performance_df.index)]
        ax.plot(plot_benchmark_df.index, plot_benchmark_df['Total_Assets'], color='orange', linestyle='--', linewidth=2.5, label=f'{Config.BENCHMARK_NAME} (è²·å…¥ä¸¦æŒæœ‰)')
        for date, row in plot_benchmark_df.iterrows():
            total_assets = row['Total_Assets']
            label = f"{total_assets/1e6:.2f}M" if total_assets >= 1e6 else f"{total_assets/1e3:.0f}k"
            ax.annotate(label, (date, total_assets), textcoords="offset points", xytext=(0, -20), ha='center', fontsize=8, color='dimgray')

    ax.set_title('ç­–ç•¥ç¸¾æ•ˆ vs. åŸºæº–æŒ‡æ•¸', fontsize=16)
    ax.set_xlabel('æ—¥æœŸ')
    ax.set_ylabel('è³‡ç”¢åƒ¹å€¼ (å…ƒ)')
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))
    ax.set_xlim(performance_df.index.min(), performance_df.index.max())
    ax.xaxis.set_major_locator(mdates.AutoDateLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    fig.autofmt_xdate()
    plt.grid(True, which='both', linestyle='--', linewidth=0.5)
    plt.legend(loc='upper left')
    plt.tight_layout()
    print("âœ… åœ–è¡¨å·²ç”¢ç”Ÿã€‚")


# ä½œç”¨: å¾ç¸¾æ•ˆ DataFrame ä¸­ï¼Œè¨ˆç®—æ¨™æº–åŒ–çš„ç¸¾æ•ˆæŒ‡æ¨™ã€‚
def calculate_performance_metrics(perf_df, initial_capital, annualization_factor):
    final_assets = perf_df['Total_Assets'].iloc[-1]
    total_return = (final_assets / initial_capital) - 1
    
    perf_df['Period_Return'] = perf_df['Total_Assets'].pct_change().fillna(0)
    num_periods = len(perf_df)
    
    annualized_return = (1 + total_return) ** (annualization_factor / num_periods) - 1 if num_periods > 1 else total_return
    annualized_volatility = perf_df['Period_Return'].std() * np.sqrt(annualization_factor)
    sharpe_ratio = annualized_return / annualized_volatility if annualized_volatility != 0 else 0
    
    rolling_max = perf_df['Total_Assets'].cummax()
    drawdown = perf_df['Total_Assets'] / rolling_max - 1
    max_drawdown = drawdown.min()
    
    return {
        "æœ€çµ‚è³‡ç”¢": final_assets, "ç¸½å ±é…¬ç‡": total_return, "å¹´åŒ–å ±é…¬ç‡": annualized_return,
        "å¹´åŒ–æ³¢å‹•ç‡": annualized_volatility, "å¤æ™®æ¯”ç‡": sharpe_ratio, "æœ€å¤§å›æ’¤": max_drawdown
    }


# ä½œç”¨: é¡¯ç¤ºä¾è‚¡ç¥¨ä»£ç¢¼å½™ç¸½çš„ç¸½äº¤æ˜“æ‘˜è¦ï¼Œä¸¦å°‡çµæœ DataFrame å›å‚³ã€‚
def display_and_get_transaction_summary(transaction_log):
    if not transaction_log:
        print("\n--- ç„¡äº¤æ˜“ç´€éŒ„å¯ä¾›å½™ç¸½ ---")
        return pd.DataFrame()
        
    trans_df = pd.DataFrame(transaction_log)
    
    buy_summary = trans_df[trans_df['Type'] == 'Buy'].groupby('StockID').agg(
        Buy_Trades=('Type', 'count'), Total_Shares_Bought=('Shares', 'sum'),
        Avg_Buy_Price=('Price', 'mean'), Total_Buy_Value=('Value', 'sum')
    )
    
    sell_summary = trans_df[trans_df['Type'].str.contains('Sell')].groupby('StockID').agg(
        Sell_Trades=('Type', 'count'), Total_Shares_Sold=('Shares', 'sum'),
        Avg_Sell_Price=('Price', 'mean'), Total_Sell_Value=('Value', 'sum')
    )
    
    summary_df = pd.concat([buy_summary, sell_summary], axis=1).fillna(0)
    summary_df['Realized_PnL'] = summary_df['Total_Sell_Value'] - summary_df['Total_Buy_Value']
    summary_df['ROI_%'] = (summary_df['Realized_PnL'] / (summary_df['Total_Buy_Value'] + 1e-6)) * 100
    summary_df = summary_df.sort_values(by='Realized_PnL', ascending=False)
    
    summary_df = summary_df.astype({
        'Buy_Trades': int, 'Total_Shares_Bought': int, 
        'Sell_Trades': int, 'Total_Shares_Sold': int
    })
    
    final_columns = [
        'Buy_Trades', 'Total_Shares_Bought', 'Avg_Buy_Price', 'Total_Buy_Value',
        'Sell_Trades', 'Total_Shares_Sold', 'Avg_Sell_Price', 'Total_Sell_Value',
        'Realized_PnL', 'ROI_%'
    ]
    summary_df = summary_df[final_columns]
    
    formatters = {
        'Avg_Buy_Price': '{:,.2f}'.format, 'Total_Buy_Value': '{:,.0f}'.format,
        'Avg_Sell_Price': '{:,.2f}'.format, 'Total_Sell_Value': '{:,.0f}'.format,
        'Realized_PnL': '{:,.0f}'.format, 'ROI_%': '{:,.2f}%'.format
    }
    
    print("\n--- å›æ¸¬ç¸½äº¤æ˜“å½™ç¸½è¡¨ (ä¾ç²åˆ©æ’åº) ---")
    print(summary_df.to_string(formatters=formatters))
    
    return summary_df


# --- 3. æ ¸å¿ƒæµç¨‹å‡½å¼ (Core Functions) ---

# ä½œç”¨: è¼‰å…¥ä¸¦è™•ç†å¸‚å ´åŸºæº–æŒ‡æ•¸çš„è³‡æ–™ã€‚
def load_benchmark_data(file_path):
    print(f"\n>>> è¼‰å…¥åŸºæº–æŒ‡æ•¸è³‡æ–™: {file_path}")
    try:
        benchmark_df = pd.read_excel(file_path)
        date_col_found, close_col_found = None, None
        possible_date_cols = ['Date', 'æ—¥æœŸ', 'å¹´æœˆæ—¥', 'äº¤æ˜“æ—¥']
        possible_close_cols = ['Close', 'æ”¶ç›¤åƒ¹', 'æ”¶ç›¤æŒ‡æ•¸', 'åƒ¹æ ¼æŒ‡æ•¸å€¼']
        
        for col in possible_date_cols:
            if col in benchmark_df.columns:
                date_col_found = col
                break
        for col in possible_close_cols:
            if col in benchmark_df.columns:
                close_col_found = col
                break
                
        if date_col_found and close_col_found:
            print(f"    - åµæ¸¬åˆ° æ—¥æœŸæ¬„ä½:'{date_col_found}', æ”¶ç›¤åƒ¹æ¬„ä½:'{close_col_found}'")
            benchmark_df = benchmark_df.rename(columns={date_col_found: 'Date', close_col_found: 'Close'})
            benchmark_df['Date'] = pd.to_datetime(benchmark_df['Date'], errors='coerce')
            benchmark_df = benchmark_df[['Date', 'Close']].sort_values('Date').dropna().reset_index(drop=True)
            print("âœ… åŸºæº–è³‡æ–™è¼‰å…¥æˆåŠŸã€‚")
            return benchmark_df
        else:
            raise ValueError("åœ¨æŒ‡æ•¸æª”æ¡ˆä¸­æ‰¾ä¸åˆ°å¯è¾¨è­˜çš„æ—¥æœŸæˆ–æ”¶ç›¤åƒ¹æ¬„ä½ã€‚")
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•è¼‰å…¥åŸºæº–æª”æ¡ˆã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        return None


# ä½œç”¨: åŸ·è¡Œå®Œæ•´çš„æ©Ÿå™¨å­¸ç¿’æµç¨‹ã€‚
def run_ml_pipeline():
    print("--- é–‹å§‹åŸ·è¡Œã€æ©Ÿå™¨å­¸ç¿’æµç¨‹ã€‘ ---")
    try:
        df = pd.read_excel(Config.FILE_PATH)
        df[Config.DATE_COL] = pd.to_datetime(df[Config.DATE_COL])
        df.sort_values(by=[Config.COMPANY_COL, Config.DATE_COL], inplace=True)
        print("âœ… æ­¥é©Ÿ 1: è³‡æ–™è®€å–æˆåŠŸã€‚")
    except Exception as e:
        print(f"âŒ æ­¥é©Ÿ 1 å¤±æ•—: {e}")
        return None, None, None, None, None

    print(f"\n>>> æ­¥é©Ÿ 2: è¨ˆç®—é æ¸¬ç›®æ¨™...")
    df[f'Future_Price_{Config.FORWARD_RETURN_DAYS}D'] = df.groupby(Config.COMPANY_COL)[Config.PRICE_COL].shift(-Config.FORWARD_RETURN_DAYS)
    df[Config.RAW_TARGET_COL] = (df[f'Future_Price_{Config.FORWARD_RETURN_DAYS}D'] / df[Config.PRICE_COL]) - 1
    df[Config.TARGET_COL] = df.groupby(Config.DATE_COL)[Config.RAW_TARGET_COL].transform(lambda x: (x - x.mean()) / x.std())
    df = df.drop(columns=[f'Future_Price_{Config.FORWARD_RETURN_DAYS}D'])
    print("âœ… é æ¸¬ç›®æ¨™è¨ˆç®—å®Œæˆã€‚")

    print("\n>>> æ­¥é©Ÿ 3: åˆ‡åˆ†è³‡æ–™é›†...")
    df_filtered = df[df[Config.DATE_COL] >= Config.DATA_START_DATE].copy()
    train_df = df_filtered[df_filtered[Config.DATE_COL] <= Config.TRAIN_END_DATE].copy()
    test_df_for_backtest = df_filtered[df_filtered[Config.DATE_COL] >= Config.TEST_START_DATE].copy()
    test_df_for_model = test_df_for_backtest.copy()
    all_cols_to_check = Config.FACTOR_COLS + [Config.TARGET_COL, Config.RAW_TARGET_COL]
    train_df.dropna(subset=all_cols_to_check, inplace=True)
    test_df_for_model.dropna(subset=all_cols_to_check, inplace=True)
    if train_df.empty or test_df_for_model.empty:
        print("âŒ éŒ¯èª¤: åˆ‡åˆ†å¾Œè³‡æ–™é›†ç‚ºç©ºã€‚")
        return None, None, None, None, None
    print(f"âœ… è³‡æ–™åˆ‡åˆ†å®Œæˆ: è¨“ç·´é›† {len(train_df)} ç­†, æ¸¬è©¦é›†(å›æ¸¬ç”¨) {len(test_df_for_backtest)} ç­†, æ¸¬è©¦é›†(æ¨¡å‹è©•ä¼°ç”¨) {len(test_df_for_model)} ç­†ã€‚")
    X_train, y_train = train_df[Config.FACTOR_COLS], train_df[Config.TARGET_COL]
    
    plot_correlation_heatmap(train_df, Config.FACTOR_COLS)

    print(f"\n>>> æ­¥é©Ÿ 4: è¶…åƒæ•¸èª¿æ ¡...")
    tscv = TimeSeriesSplit(n_splits=Config.CV_SPLITS)
    random_search = RandomizedSearchCV(
        estimator=LGBMRegressor(random_state=Config.RANDOM_STATE, n_jobs=-1, verbosity=-1),
        param_distributions=Config.RANDOM_SEARCH_PARAM_DIST, 
        n_iter=Config.N_ITER_SEARCH, cv=tscv, n_jobs=-1, 
        scoring='r2', verbose=1, random_state=Config.RANDOM_STATE
    )
    random_search.fit(X_train, y_train)
    best_params = random_search.best_params_
    print(f"âœ… èª¿æ ¡å®Œæˆã€‚æœ€ä½³åƒæ•¸: {best_params}")

    print(f"\n>>> æ­¥é©Ÿ 5: å› å­ç¯©é¸...")
    base_model = LGBMRegressor(**best_params, random_state=Config.RANDOM_STATE, n_jobs=-1, verbosity=-1)
    selector = SelectFromModel(base_model, max_features=Config.N_FEATURES_TO_SELECT, threshold=-np.inf)
    selector.fit(X_train, y_train)
    selected_features = X_train.columns[selector.get_support()].tolist()
    print(f"âœ… ç¯©é¸å®Œæˆï¼Œé¸å‡ºç‰¹å¾µ: {selected_features}")

    print("\n>>> æ­¥é©Ÿ 6: è¨“ç·´æœ€çµ‚æ¨¡å‹...")
    X_train_selected = X_train[selected_features]
    final_model = LGBMRegressor(**best_params, random_state=Config.RANDOM_STATE, n_jobs=-1, verbosity=-1)
    final_model.fit(X_train_selected, y_train)
    print("âœ… æœ€çµ‚æ¨¡å‹è¨“ç·´å®Œæˆã€‚")

    print("\n>>> æ­¥é©Ÿ 7: è©•ä¼°æ¨¡å‹èƒ½åŠ›...")
    X_test_selected = test_df_for_model[selected_features]
    y_test = test_df_for_model[Config.TARGET_COL]
    pred_train = final_model.predict(X_train_selected)
    pred_test = final_model.predict(X_test_selected)
    r2_train, r2_test = r2_score(y_train, pred_train), r2_score(y_test, pred_test)
    ic_train, _ = spearmanr(y_train, pred_train)
    ic_test, _ = spearmanr(y_test, pred_test)
    print("--- æ¨¡å‹èƒ½åŠ›è©•ä¼°çµæœ ---")
    print(f"  - è¨“ç·´é›† R-squared: {r2_train:.4f}, æ¸¬è©¦é›† R-squared: {r2_test:.4f}")
    print(f"  - è¨“ç·´é›† IC: {ic_train:.4f}, æ¸¬è©¦é›† IC: {ic_test:.4f}")
    print("-" * 30)
    
    feature_importance_df = pd.DataFrame({
        'Factor': selected_features,
        'Importance': final_model.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    
    plot_feature_importance(feature_importance_df['Importance'], feature_importance_df['Factor'], 'LightGBM Regressor')
    print("\n--- æ©Ÿå™¨å­¸ç¿’æµç¨‹çµæŸ ---")
    return final_model, selected_features, df, test_df_for_backtest, feature_importance_df


# ä½œç”¨: ç¨ç«‹è¨ˆç®—åŸºæº–æŒ‡æ•¸çš„å›æ¸¬ç¸¾æ•ˆã€‚
def calculate_benchmark_performance(benchmark_df, strategy_perf_df, initial_capital, annualization_factor):
    print("\n>>> è¨ˆç®—åŸºæº–ç¸¾æ•ˆ...")
    print(f"    - ç­–ç•¥å›æ¸¬æ—¥æœŸ: {strategy_perf_df.index.min().date()} åˆ° {strategy_perf_df.index.max().date()}")
    print(f"    - åŸºæº–æŒ‡æ•¸æ—¥æœŸ: {benchmark_df[Config.DATE_COL].min().date()} åˆ° {benchmark_df[Config.DATE_COL].max().date()}")
    
    benchmark_perf_df = benchmark_df[benchmark_df[Config.DATE_COL].isin(strategy_perf_df.index)].copy()
    
    if benchmark_perf_df.empty:
        print("    - âš ï¸ è­¦å‘Šï¼šæ—¥æœŸç¯„åœæ²’æœ‰é‡ç–Šï¼Œç„¡æ³•æ¯”è¼ƒã€‚")
        return None, None
        
    print(f"    - âœ… æ—¥æœŸæˆåŠŸå°é½Šï¼æ‰¾åˆ° {len(benchmark_perf_df)} ç­†é‡ç–Šè³‡æ–™ã€‚")
    first_day_index_val = benchmark_perf_df['Close'].iloc[0]
    benchmark_perf_df['Total_Assets'] = (benchmark_perf_df['Close'] / first_day_index_val) * initial_capital
    benchmark_metrics = calculate_performance_metrics(benchmark_perf_df.copy(), initial_capital, annualization_factor)
    benchmark_perf_df.set_index('Date', inplace=True)
    return benchmark_perf_df, benchmark_metrics


# ä½œç”¨: åŸ·è¡Œã€Œè´å®¶çºŒæŠ±+ç§»å‹•åœæã€ç­–ç•¥çš„å›æ¸¬ã€‚
def run_backtesting_strategy(model, features, full_df, test_df, benchmark_df):
    print("\n--- é–‹å§‹åŸ·è¡Œã€V28.1 å›æ¸¬æµç¨‹ (è´å®¶çºŒæŠ± + ç§»å‹•åœæ)ã€‘---")
    if test_df.empty:
        print("âŒ å›æ¸¬å¤±æ•—ï¼šæ¸¬è©¦é›†ç‚ºç©ºã€‚")
        return {}
    
    cash = Config.INITIAL_CAPITAL
    holdings = {}
    performance_log = []
    transaction_log = []
    rebalancing_selections_log = []
    price_lookup = test_df.set_index([Config.DATE_COL, Config.COMPANY_COL])[Config.PRICE_COL]
    rebalance_periods = sorted(test_df[Config.DATE_COL].dt.to_period(Config.REBALANCE_FREQUENCY).unique())
    print(f"ç­–ç•¥å°‡ä»¥ã€Œ{Config.REBALANCE_FREQUENCY}ã€ç‚ºé€±æœŸé€²è¡Œæ›å€‰ï¼Œå…± {len(rebalance_periods)} æ¬¡ã€‚")

    for period in rebalance_periods:
        start_of_period_data = test_df[test_df[Config.DATE_COL].dt.to_period(Config.REBALANCE_FREQUENCY) == period]
        if start_of_period_data.empty:
            continue
            
        current_date = start_of_period_data[Config.DATE_COL].min()
        print(f"\n-+-+-+- ğŸ“… {period} (åŸ·è¡Œæ—¥: {current_date.date()}) æ›å€‰é–‹å§‹ -+-+-+-")
        
        # ... (å¾ŒçºŒçš„åœæã€ç›¤é»ã€é¸è‚¡ã€äº¤æ˜“é‚è¼¯èˆ‡ V27/V28 ç‰ˆæœ¬ç›¸åŒ) ...
        print("  [é¢¨æ§] æª¢æŸ¥å€‹è‚¡ç§»å‹•åœæ...")
        stopped_out_stocks = []
        for stock_id, data in list(holdings.items()):
            current_price = price_lookup.get((current_date, stock_id))
            if current_price is None: continue
            new_high_water_mark = max(data['high_water_mark'], current_price)
            holdings[stock_id]['high_water_mark'] = new_high_water_mark
            stop_loss_price = new_high_water_mark * (1 - Config.INDIVIDUAL_STOP_LOSS_PCT)
            if current_price < stop_loss_price:
                print(f"    ğŸš¨ {stock_id} è§¸ç™¼ç§»å‹•åœæï¼(ç¾åƒ¹ {current_price:.2f} < åœæåƒ¹ {stop_loss_price:.2f})")
                value = data['shares'] * current_price
                cost = value * (Config.TRANSACTION_FEE_RATE + Config.TRANSACTION_TAX_RATE)
                cash += value - cost
                transaction_log.append({'Date': current_date, 'Type': 'StopLoss Sell', 'StockID': stock_id, 'Shares': data['shares'], 'Price': current_price, 'Value': value, 'Cost': cost, 'Cash_After_Trade': cash})
                stopped_out_stocks.append(stock_id)
        for stock_id in stopped_out_stocks:
            del holdings[stock_id]
        
        holdings_value = sum(data['shares'] * price_lookup.get((current_date, stock_id), 0) for stock_id, data in holdings.items())
        total_assets = holdings_value + cash
        performance_log.append({'Date': current_date, 'Total_Assets': total_assets, 'Holdings_Value': holdings_value, 'Cash': cash, 'Transaction_Costs': 0})
        print(f"  [ç›¤é»] ç¸½è³‡ç”¢: {total_assets:,.0f}, æŒè‚¡å¸‚å€¼: {holdings_value:,.0f}, ç¾é‡‘: {cash:,.0f}")
        
        prediction_df = start_of_period_data[start_of_period_data[Config.DATE_COL] == current_date].copy()
        X_pred = prediction_df[features]
        predictions = model.predict(X_pred)
        results_df = prediction_df[[Config.COMPANY_COL]].copy()
        results_df['prediction_score'] = predictions
        target_stocks_df = results_df.sort_values(by='prediction_score', ascending=False).head(Config.TOP_N_STOCKS)
        target_stock_ids = set(target_stocks_df[Config.COMPANY_COL].tolist())
        print(f"  [æ±ºç­–] æœ¬æœŸæ–°ç›®æ¨™åå–®: {list(target_stock_ids)}")
        rebalancing_selections_log.append({'Date': current_date, 'Selected_Stocks': ", ".join(list(target_stock_ids))})

        current_stock_ids = set(holdings.keys())
        stocks_to_sell = current_stock_ids - target_stock_ids
        stocks_to_buy = target_stock_ids - current_stock_ids
        stocks_to_hold = current_stock_ids & target_stock_ids
        print(f"    - æŒçºŒæŒæœ‰: {list(stocks_to_hold) if stocks_to_hold else 'ç„¡'}")
        print(f"    - è¨ˆç•«è³£å‡º: {list(stocks_to_sell) if stocks_to_sell else 'ç„¡'}")
        print(f"    - è¨ˆç•«è²·å…¥: {list(stocks_to_buy) if stocks_to_buy else 'ç„¡'}")
        
        sell_cost, buy_cost = 0, 0
        if stocks_to_sell:
            print("  --- ç•¶æœŸäº¤æ˜“è©³æƒ…: è³£å‡º ---")
            for stock_id in list(stocks_to_sell):
                price = price_lookup.get((current_date, stock_id)); shares = holdings[stock_id]['shares']
                if price:
                    value = shares * price; cost = value * (Config.TRANSACTION_FEE_RATE + Config.TRANSACTION_TAX_RATE); cash += value - cost; sell_cost += cost
                    transaction_log.append({'Date': current_date, 'Type': 'Sell', 'StockID': stock_id, 'Shares': shares, 'Price': price, 'Value': value, 'Cost': cost, 'Cash_After_Trade': cash})
                    print(f"      -> {stock_id}: è³£å‡º {shares:,} è‚¡ @ {price:.2f}å…ƒ, é‡‘é¡ {value:,.0f}å…ƒ")
                else:
                    print(f"      -> âš ï¸ [å¼·åˆ¶å¹³å€‰] æ‰¾ä¸åˆ° {stock_id} ç•¶æ—¥åƒ¹æ ¼ï¼Œè©²éƒ¨ä½å°‡å¾æŒè‚¡ä¸­ç§»é™¤ï¼Œåƒ¹å€¼è¦–ç‚º0ã€‚")
                    transaction_log.append({'Date': current_date, 'Type': 'Forced Sell', 'StockID': stock_id, 'Shares': shares, 'Price': 0, 'Value': 0, 'Cost': 0, 'Cash_After_Trade': cash})
                del holdings[stock_id]
        if sell_cost > 0: print(f"    - è³£å‡ºå®Œæˆå¾Œï¼Œç¾é‡‘æ›´æ–°ç‚º: {cash:,.0f} å…ƒ")
        
        if stocks_to_buy:
            print("  --- ç•¶æœŸäº¤æ˜“è©³æƒ…: è²·å…¥ ---")
            capital_per_stock = cash / len(stocks_to_buy) if len(stocks_to_buy) > 0 else 0
            print(f"    - å¯ç”¨ç¾é‡‘ {cash:,.0f} å…ƒï¼Œé è¨ˆç‚ºæ¯æ”¯æ–°è‚¡åˆ†é… {capital_per_stock:,.0f} å…ƒ")
            for stock_id in stocks_to_buy:
                price = price_lookup.get((current_date, stock_id))
                if price:
                    cost_per_share = price * (1 + Config.TRANSACTION_FEE_RATE)
                    shares_to_buy = floor(capital_per_stock / cost_per_share) if cost_per_share > 0 else 0
                    if shares_to_buy > 0:
                        value = shares_to_buy * price; fee = value * Config.TRANSACTION_FEE_RATE
                        if cash >= value + fee:
                            cash -= (value + fee); holdings[stock_id] = {'shares': shares_to_buy, 'high_water_mark': price}; buy_cost += fee
                            transaction_log.append({'Date': current_date, 'Type': 'Buy', 'StockID': stock_id, 'Shares': shares_to_buy, 'Price': price, 'Value': value, 'Cost': fee, 'Cash_After_Trade': cash})
                            print(f"      -> {stock_id}: è²·å…¥ {shares_to_buy:,} è‚¡ @ {price:.2f}å…ƒ, é‡‘é¡ {value:,.0f}å…ƒ")
                        else: print(f"      - [è­¦å‘Š] ç¾é‡‘ä¸è¶³ï¼Œç„¡æ³•è²·å…¥ {shares_to_buy:,} è‚¡ {stock_id}")
        
        performance_log[-1]['Transaction_Costs'] = sell_cost + buy_cost
        print(f"  [åŸ·è¡Œ] æ›å€‰å®Œæˆã€‚å‰©é¤˜ç¾é‡‘: {cash:,.0f}")
    
    if holdings:
        last_trading_day = test_df[test_df[Config.DATE_COL].dt.year == test_df[Config.DATE_COL].max().year][Config.DATE_COL].max()
        print(f"\n-+-+-+- ğŸ“… {last_trading_day.date()} (å¹´çµ‚å¼·åˆ¶å¹³å€‰) -+-+-+-")
        print(f"  [çµç®—] æ­£åœ¨ä»¥å¹´åº•æ”¶ç›¤åƒ¹è³£å‡ºæ‰€æœ‰å‰©é¤˜æŒè‚¡...")
        final_sell_cost = 0
        for stock_id, data in list(holdings.items()):
            price = price_lookup.get((last_trading_day, stock_id))
            if price:
                value = data['shares'] * price; cost = value * (Config.TRANSACTION_FEE_RATE + Config.TRANSACTION_TAX_RATE); cash += value - cost; final_sell_cost += cost
                transaction_log.append({'Date': last_trading_day, 'Type': 'Year-End Sell', 'StockID': stock_id, 'Shares': data['shares'], 'Price': price, 'Value': value, 'Cost': cost, 'Cash_After_Trade': cash})
                print(f"    -> è³£å‡º: {stock_id}, {data['shares']:,} è‚¡ @ {price:.2f} å…ƒ")
        holdings.clear()
        final_assets = cash
        performance_log.append({'Date': last_trading_day, 'Total_Assets': final_assets, 'Holdings_Value': 0, 'Cash': final_assets, 'Transaction_Costs': final_sell_cost})
        print(f"    - å¹³å€‰å®Œæˆã€‚æœ€çµ‚ç¾é‡‘é¤˜é¡: {final_assets:,.0f} å…ƒ")

    if not performance_log:
        print("\nâŒ å›æ¸¬çµæŸï¼Œç„¡ä»»ä½•ç´€éŒ„ã€‚")
        return {}
    
    strategy_perf_df = pd.DataFrame(performance_log).set_index('Date')
    transaction_summary_df = display_and_get_transaction_summary(transaction_log)
    rebalancing_selections_df = pd.DataFrame(rebalancing_selections_log)
    full_transaction_log_df = pd.DataFrame(transaction_log)
    
    return {
        "strategy_perf": strategy_perf_df, "benchmark_data": benchmark_df,
        "transaction_summary": transaction_summary_df, "rebalancing_selections": rebalancing_selections_df,
        "full_transaction_log": full_transaction_log_df
    }

# --- 4. ä¸»åŸ·è¡Œå‡½å¼ (Main) ---
def main():
    print("--- å°ˆæ¡ˆåŸ·è¡Œå•Ÿå‹• ---")
    
    benchmark_df = load_benchmark_data(Config.BENCHMARK_FILE_PATH)
    ml_results = run_ml_pipeline()
    
    if not ml_results:
        print("\nâŒ å› æ©Ÿå™¨å­¸ç¿’æµç¨‹å¤±æ•—ï¼Œå·²çµ‚æ­¢åŸ·è¡Œã€‚")
        return

    final_model, selected_features, full_df, test_df, feature_importance_df = ml_results
    backtest_results = run_backtesting_strategy(final_model, selected_features, full_df, test_df, benchmark_df)
    
    if not backtest_results:
        print("\nâŒ å› å›æ¸¬æµç¨‹å¤±æ•—ï¼Œå·²çµ‚æ­¢åŸ·è¡Œã€‚")
        return
        
    print("\n>>> æ­£åœ¨å°‡æ‰€æœ‰åˆ†æçµæœå¯«å…¥å–®ä¸€ Excel æª”æ¡ˆ...")
    try:
        with pd.ExcelWriter(Config.REPORT_FILE_PATH, engine='xlsxwriter') as writer:
            periods_per_year = {'M': 12, 'Q': 4}
            annualization_factor = periods_per_year.get(Config.REBALANCE_FREQUENCY, 12)
            strategy_metrics = calculate_performance_metrics(backtest_results["strategy_perf"], Config.INITIAL_CAPITAL, annualization_factor)
            
            benchmark_perf_df, benchmark_metrics = None, None
            if backtest_results["benchmark_data"] is not None:
                benchmark_perf_df, benchmark_metrics = calculate_benchmark_performance(backtest_results["benchmark_data"], backtest_results["strategy_perf"], Config.INITIAL_CAPITAL, annualization_factor)

            comparison_data = {"ç­–ç•¥": strategy_metrics}
            if benchmark_metrics:
                comparison_data[Config.BENCHMARK_NAME] = benchmark_metrics
            
            comparison_df = pd.DataFrame(comparison_data)
            comparison_df.to_excel(writer, sheet_name='ç¸¾æ•ˆç¸½è¦½ (Performance_Summary)')
            # åœ¨å®ƒçš„å‰é¢ï¼ŒåŠ å…¥ä»¥ä¸‹è¨ˆç®—ï¼š
            total_importance = feature_importance_df['Importance'].sum()
            feature_importance_df['Normalized_Importance_%'] = (feature_importance_df['Importance'] / total_importance) * 100

            # ä¿®æ”¹å¯«å…¥ Excel çš„ç¨‹å¼ç¢¼ï¼Œå°‡æ–°æ¬„ä½ä¹Ÿå¯«å…¥
            feature_importance_df.to_excel(writer, sheet_name='æœ€ä½³å› å­èˆ‡æ¬Šé‡ (Feature_Importance)', index=False)
            backtest_results["rebalancing_selections"].to_excel(writer, sheet_name='æ¯æœŸæŒè‚¡é¸æ“‡ (Periodic_Selections)', index=False)
            backtest_results["transaction_summary"].to_excel(writer, sheet_name='ç¸½äº¤æ˜“å½™ç¸½ (Transaction_Summary)')
            backtest_results["full_transaction_log"].to_excel(writer, sheet_name='è©³ç´°äº¤æ˜“ç´€éŒ„ (Full_Log)', index=False)
            backtest_results["strategy_perf"].to_excel(writer, sheet_name='ç­–ç•¥æ¬Šç›Šæ›²ç·š (Performance_Curve)')
        
        print(f"âœ… æ‰€æœ‰å ±å‘Šå·²æˆåŠŸå„²å­˜è‡³: {Config.REPORT_FILE_PATH}")
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤ï¼šå ±è¡¨å„²å­˜å¤±æ•—ã€‚åŸå› : {e}")

    plot_backtest_results(backtest_results["strategy_perf"], benchmark_perf_df)
    print("\n>>> æ‰€æœ‰æµç¨‹åŸ·è¡Œå®Œç•¢ï¼Œæ­£åœ¨é¡¯ç¤ºåœ–è¡¨...")
    plt.show()


# --- 5. ç¨‹å¼é€²å…¥é» (Entry Point) ---
if __name__ == "__main__":
    start_time = time.time()
    main()
    end_time = time.time()
    
    elapsed_time = end_time - start_time
    minutes = int(elapsed_time // 60)
    seconds = int(elapsed_time % 60)
    
    print(f"\n--- ç¸½åŸ·è¡Œæ™‚é–“ ---")
    print(f"â³ æœ¬æ¬¡å®Œæ•´æµç¨‹ç¸½å…±è€—æ™‚: {minutes} åˆ† {seconds} ç§’ ({elapsed_time:.2f} ç§’)")
